{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "117ef51a",
   "metadata": {},
   "source": [
    "# CHAPTER - 10: Dimensionality Reduction Using Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74374cc5",
   "metadata": {},
   "source": [
    "Reducing Dimensionality of a feature matrix by creating a new feature(with fewer dimensions) is called Feature Extraction.\n",
    "\n",
    "Selecting high quality features, informative features and dropping less useful features called Feature Selection.\n",
    "\n",
    "There are three types of feature selection methods: \n",
    "   1) Filter: Selects best features by thier statistical properties.\n",
    "   2) Wrapper: Use trail and error to find subset of features that produce models with high quality prediction.\n",
    "   3) Embedded: Select the best feature subset as part or as an extension of a learning algorithms training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf5d7b3",
   "metadata": {},
   "source": [
    "## 10.1 Thresholding Numerical Feature Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3258ac7b",
   "metadata": {},
   "source": [
    "For Numerical Features:\n",
    "\n",
    "Removing low variance features from a set of features.\n",
    "\n",
    "VarianceThreshold: To remove low variance features.\n",
    "\n",
    "Variance thresholding is one of the most basic approaches of feature selection.\n",
    "\n",
    "While applying VT:\n",
    "1) Variance is not centered i.e., it will not work when features contain different sets(ex: dollars set and years set)\n",
    "2) Variance threshold value is selected manually, we have to use our judgment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef969bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d65eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abe96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating features and target\n",
    "\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b557a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating thresholder\n",
    "\n",
    "thresholder = VarianceThreshold(threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08987cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating High Variance Feature Matrix\n",
    "\n",
    "highVariance_ft = thresholder.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ce1332e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 1.4, 0.2],\n",
       "       [4.9, 1.4, 0.2],\n",
       "       [4.7, 1.3, 0.2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High Variance Feature Matrix\n",
    "\n",
    "highVariance_ft[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027c06b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68112222, 0.18871289, 3.09550267, 0.57713289])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to view variances\n",
    "\n",
    "thresholder.fit(features).variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14e430c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the feature is standardized(i.e, mean = 0 and variance = 1), VT does not work.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fee1c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize feature matrix\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d28062ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating variance of each feature\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "selector.fit(features_std).variances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16231999",
   "metadata": {},
   "source": [
    "## 10.2 Thresholding Binary Feature Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a22d756",
   "metadata": {},
   "source": [
    "For Binary Feature:\n",
    "\n",
    "Removing low variance set of features from binary categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c53462af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ac1a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a feature matrix with:\n",
    "#     1) Feature 0: 80% class 0\n",
    "#     2) Feature 1: 80% class 1\n",
    "#     3) Feature 2: 60% class 0 & 40% class 1\n",
    "\n",
    "features = [[0,1,0],\n",
    "           [0,1,1],\n",
    "           [0,1,0],\n",
    "           [0,1,1],\n",
    "           [0,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24986066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Threshold by variance\n",
    "\n",
    "thresholder = VarianceThreshold(threshold = (.75 * (1 - .75)))\n",
    "thresholder.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866d396",
   "metadata": {},
   "source": [
    "## 10.3 Handling Highly Correlated Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86340a64",
   "metadata": {},
   "source": [
    "Handling features when some of the features are correlated. \n",
    "\n",
    "Checking if highly correlated features exist and dropping them if they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bc56ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebe22dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matrix with highlt correlated features\n",
    "\n",
    "features = np.array([[1,1,1],\n",
    "                    [2,2,0],\n",
    "                    [3,3,1],\n",
    "                    [4,4,0],\n",
    "                    [5,5,1],\n",
    "                    [6,6,0],\n",
    "                    [7,7,1],\n",
    "                    [8,7,0],\n",
    "                    [9,7,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff043533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting feature matrix into Dataframe\n",
    "\n",
    "dataframe = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d60d10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating correlation matrix\n",
    "\n",
    "corr_mat = dataframe.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3733cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting upper traingle of correlation matrix\n",
    "\n",
    "upper = corr_mat.where(np.triu(np.ones(corr_mat.shape), k = 1).astype(np.bool_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ae9a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding index of feature columns with correlation greater than 0.95\n",
    "\n",
    "indexes_to_drop = [ column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9860681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  2\n",
       "0  1  1\n",
       "1  2  0\n",
       "2  3  1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# droping the features\n",
    "\n",
    "dataframe.drop(dataframe.columns[indexes_to_drop], axis = 1).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78b75005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.976103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.034503</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  1.000000  0.976103  0.000000\n",
       "1  0.976103  1.000000 -0.034503\n",
       "2  0.000000 -0.034503  1.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first:creating Correlation Matrix of all features\n",
    "\n",
    "dataframe.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c6869c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2\n",
       "0 NaN  0.976103  0.000000\n",
       "1 NaN       NaN  0.034503\n",
       "2 NaN       NaN       NaN"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second: we check the upper correlation matrix\n",
    "\n",
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3319b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third: we remove one feature from each of those pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119faede",
   "metadata": {},
   "source": [
    "## 10.4 Removing Irrelevant Features for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cffe8f0",
   "metadata": {},
   "source": [
    "Removing irrelevant features from categorical target vector.\n",
    "\n",
    "We need to calculate Chi-square if the statistic if the features are categorical.\n",
    "\n",
    "***Chi-square is used to test the independence of categorical variables.\n",
    "\n",
    "If the target vector is independent of the feature variable, then it contains no information we can use for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f5d0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "498fb2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading iris dataset\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e10c4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data to categorical data by changing it to integers\n",
    "\n",
    "features = features.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4a1c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting 2 features with highest chi-sqquared statistic using \"SelectKBest\"\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, k = 2)\n",
    "features_kbest = chi2_selector.fit_transform(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "847ca6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 3\n"
     ]
    }
   ],
   "source": [
    "# show the sizes\n",
    "\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb8747",
   "metadata": {},
   "source": [
    "We can use \"SelectPercentile\" to select top n percent features instead of selecting a specific number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "feb57d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading SelectPercentile library\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70b8bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 75% of features with highest F-values\n",
    "\n",
    "fvalue_selector = SelectPercentile(f_classif, percentile = 75)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfc15709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of feature: 4\n",
      "Reduced number of features: 3\n"
     ]
    }
   ],
   "source": [
    "# Showing the reduced results\n",
    "\n",
    "print(\"Original number of feature:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a831d",
   "metadata": {},
   "source": [
    "## 10.5 Recursively Eliminating Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706ef8a",
   "metadata": {},
   "source": [
    "Selecting best features to keep.\n",
    "\n",
    "We use Scikit learns RFECV for Recursive Feature Elimination(RFE) using Cross-Validation(CV).\n",
    "\n",
    "We repeatedly train the model by removing a feature each time until model performance becomes worse, the remaining features are the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b352bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "\n",
    "import warnings\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "739f4976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supressing warnings\n",
    "\n",
    "warnings.filterwarnings(action = \"ignore\", module = 'scipy', message = '^internal gelsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84ec1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating feature matrix, target vector and true coefficients\n",
    "\n",
    "features, target = make_regression(n_samples = 10000,\n",
    "                                  n_features = 100,\n",
    "                                  n_informative = 2,\n",
    "                                  random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "016441f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a linear regression\n",
    "\n",
    "ols = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e707e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.51278885,  1.06522186, -0.25592483,  1.23913282,  0.82100186,\n",
       "         0.22228094],\n",
       "       [-1.21135854,  1.34456723,  1.03992104,  1.48084905, -0.08293439,\n",
       "        -1.12891946],\n",
       "       [ 0.03890833, -0.91845034, -0.14531089,  1.73433529,  2.29769945,\n",
       "        -1.11008524],\n",
       "       ...,\n",
       "       [ 0.71536151, -0.95047313,  1.74506759,  0.28464179, -2.13830256,\n",
       "         1.96873384],\n",
       "       [-1.30366012, -0.50997804, -0.10368359,  0.34521149,  0.40692248,\n",
       "         0.22985492],\n",
       "       [-0.13767296, -0.76122978, -1.23733457, -0.62409358,  0.02734765,\n",
       "        -1.02436197]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recursively eliminate the features\n",
    "\n",
    "rfecv = RFECV(estimator = ols, step = 1, scoring = 'neg_mean_squared_error')\n",
    "rfecv.fit(features, target)\n",
    "rfecv.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "28e34afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once RFE is conducted we can see the number of features we should keep\n",
    "\n",
    "rfecv.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cac521f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also see which of the features we can keep\n",
    "\n",
    "rfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5643a905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68, 62, 26, 50, 70, 56, 78, 69, 38, 18, 83, 33,  6, 24, 61, 52,  2,\n",
       "       54,  1, 28, 22, 46,  4, 47, 34, 67, 75, 49, 89, 90, 20, 35, 82, 71,\n",
       "       27, 79, 51, 53, 57, 63,  1, 58, 74, 13, 39, 21, 36, 17, 84, 86, 77,\n",
       "       25, 91, 37, 40, 94, 85,  7, 44, 93, 11,  8, 31, 42, 41, 73,  1, 14,\n",
       "       30,  3,  5, 81, 87, 48, 55, 65,  9, 12, 80, 15, 59, 43, 60, 64, 10,\n",
       "       29, 92, 76,  1,  1, 88, 23, 95, 45, 72,  1, 66, 32, 16, 19])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see the rankings of the features\n",
    "\n",
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71472fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
