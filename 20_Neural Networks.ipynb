{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa204bb4",
   "metadata": {},
   "source": [
    "# CHAPTER - 20: Neural Networks\n",
    "\n",
    "At the heart of neural networks is the unit(called a node or neuron).\n",
    "\n",
    "A unit takes one more inputs, multiplies each input by a parameter(called weight), sums the weighted inputs values along with some bias value, then feeds the value into an activation function. This output is then sent forward to other neurals deeper in the neural network.\n",
    "\n",
    "Feedforward neural networks - also called multilayer perceptron - are the simplest artifical neural network used in any real-world setting.\n",
    "\n",
    "Neural network can be visualized as a series of connected layers that form a network connecting an obserevation's feature values at one end, and target value at the other end.\n",
    "\n",
    "The name feedforward comes from the fact that an observations feature values are fed \"forward\" through the network, with eac layer successively transforming the feature values with the goal that the output at the end is the same as the targe's value.\n",
    "\n",
    "Feedforward neural networks contain three types of layers of units:\n",
    "1. At the start of neural network -> input layer.(if an observation has 100 features, the input layer has 100 nodes.)\n",
    "2. At the end of the neural network -> output layer with.(transforms the o/p of the hidden layers into values useful for task at hand, like for binary classification to scale its output to 0 or 1)\n",
    "3. In between input and output layers -> hidden layers(which aren't hidden at all, these transforms the input feature values to output layers.)\n",
    "\n",
    "Neural networks with many hidden layers(eg., 10, 100, 1000) are considered ***\"deep networks\"*** and their applications are called deep learning.\n",
    "\n",
    "Neural networks are typically created with all parammeters initialized as small random values from a a Gaussian or normal uniform. Once the observations are fed through the network, the outputted value is compared with the obswervations true value using a loss function, this is called ***forward propogation***.\n",
    "\n",
    "Next an algorithm goes backwards through the network identifying how much each parameter contributed to the error between the predicted and true values, called ***backpropogation***. At each parameter the optimization algorithm determines how much each weight should be adjusted to improve the output.\n",
    "\n",
    "Neural networks learn by repeating this process of forward propogation and backpropogation for every observation in the training data multiple times, iteratively updating the values of the parameters.\n",
    "\n",
    "Each time all the observations have been sent through the network is called an ***epoch*** and training typically consists of multiple epochs.\n",
    "\n",
    "Neural networks created using Keras code can be trained using both CPUs and GPU. Whe we have larger networks and more training data, training uusing CPUs is significantly slower than training using GPUs.\n",
    "\n",
    "## 20.1 Preprocessing Data for Neural Networks\n",
    "\n",
    "Standardizing each feature using StandardScalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f1748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df139dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating features\n",
    "features = np.array([[-100.1, 3240.1],\n",
    "                    [-200.2, -234.1],\n",
    "                    [5000.5, 150.1],\n",
    "                    [6000.6, -125.1],\n",
    "                    [9000.9, -673.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b5e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating scalar\n",
    "\n",
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12d5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the features\n",
    "\n",
    "features_standardized = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d0ec46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12541308,  1.96429418],\n",
       "       [-1.15329466, -0.50068741],\n",
       "       [ 0.29529406, -0.22809346],\n",
       "       [ 0.57385917, -0.42335076],\n",
       "       [ 1.40955451, -0.81216255]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show features\n",
    "\n",
    "features_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "227282c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  0\n",
      "Standard deviation:  0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: \", round(features_standardized[:,0].mean()))\n",
    "print(\"Standard deviation: \", features_standardized[:,0].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0433b7a0",
   "metadata": {},
   "source": [
    "Typically, a neural network's parameters are initialized(i.e., created) as small random numbers. Neural networks often behavae poorly when the feature values are much larger than parameter values. Since an observations feature values are combined as they pass through individual units, it is important that all features have the same scacle. For all these reasons it is a best practice to standardize the each feature such that the faeture's values have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30cbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d4fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c59894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a4abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe148ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e13b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538c8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67cef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e13c552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac1b33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
