{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f6c4493",
   "metadata": {},
   "source": [
    "# CHAPTER-5 Handling Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b33acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all Categorical data is same.\n",
    "\n",
    "# Nominal: Sets of categories with no ordering is called \"Nominal\". \n",
    "\n",
    "#     Ex:(Blue, Red, Green), (Man, Woman), (Apple, Banana, Orange)\n",
    "    \n",
    "# Ordinal: When set of categories have natural ordering its called \"Ordinal\".\n",
    "\n",
    "#     Ex: (Low, Medium, High), (Young, Old)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ef64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-nearest neighbor:\n",
    "#     distance between 2 observations(Euclidean distance)\n",
    "    \n",
    "# ***This calculting distance is not possible if we are working on strings.\n",
    "#     Convert this to Numerical data using transformation that conveys the information in the categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21136103",
   "metadata": {},
   "source": [
    "## 5.1 Encoding Nominal Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0517fc",
   "metadata": {},
   "source": [
    "Nominal variables: variables with no ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e43e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1098063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating feature\n",
    "\n",
    "feature = np.array([[\"Texas\"],\n",
    "                   [\"California\"],\n",
    "                   [\"Texas\"],\n",
    "                   [\"Delaware\"],\n",
    "                   [\"Texas\"]])\n",
    "# array elements reffered as class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30c12181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating one-hot encoder\n",
    "\n",
    "one_hot = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25c02c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encode feature\n",
    "one_hot.fit_transform(feature)\n",
    "\n",
    "# when the class appears it gives 1s otherwise 0s in the encoded array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24ba5a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view feature classes\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33d0a2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Texas', 'California', 'Texas', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to reverse the one_hot encoding\n",
    "\n",
    "one_hot.inverse_transform(one_hot.fit_transform(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ba5bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on-hot encoding can also be done using pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5dd8898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   California  Delaware  Texas\n",
       "0           0         0      1\n",
       "1           1         0      0\n",
       "2           0         0      1\n",
       "3           0         1      0\n",
       "4           0         0      1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(feature[:,0])\n",
    "\n",
    "# when the class appears it gives 1s otherwise 0s in the encoded array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99268f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what differentiates scikit learn from pandas is its ability to handle lists with multiple classes\n",
    "\n",
    "# Creating a multiclass feature\n",
    "multiclass_feature = [(\"Texas\", \"Florida\"),\n",
    "                      (\"California\", \"Alabama\"),\n",
    "                      (\"Texas\", \"Florida\"),\n",
    "                      (\"Delware\", \"Florida\"),\n",
    "                      (\"Texas\", \"Alabama\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f27323f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating multiclass on-hot encoder\n",
    "\n",
    "one_hot_multiclass = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6654fcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_multiclass.fit_transform(multiclass_feature)\n",
    "\n",
    "# when the class appears it gives 1s otherwise 0s in the encoded array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9f8fd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'California', 'Delware', 'Florida', 'Texas'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_multiclass.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaac7f1",
   "metadata": {},
   "source": [
    "## 5.2 Encoding ordinal categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb5cb9",
   "metadata": {},
   "source": [
    "Ordinal variables: variables with natural ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "267f09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace() method to transform string labels to numerical equivalents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba74ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a featurre\n",
    "ordinal_df = pd.DataFrame({\"Score\":[\"Low\", \"Low\", \"Medium\", \"Medium\", \"High\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cdf81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a score mapper\n",
    "score_mapper = {\"Low\":1,\n",
    "                \"Medium\":2,\n",
    "                \"High\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a5c70cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          1\n",
       "1                          1\n",
       "2                          2\n",
       "3                          2\n",
       "4                          3\n",
       "5    Barely More Than Medium\n",
       "Name: Score, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_df[\"Score\"].replace(score_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "080c4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_df_1 = pd.DataFrame({\"Score\":[\"Low\", \"Low\", \"Medium\", \"Medium\", \"High\",\"Barely More Than Medium\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "369f53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a score mapper\n",
    "score_mapper_1 = {\"Low\":1,\n",
    "                \"Medium\":2,\n",
    "                 \"Barely More Than Medium\":3,\n",
    "                \"High\":4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d3cf1df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    4\n",
       "5    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_df_1[\"Score\"].replace(score_mapper_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72b45239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a score mapper\n",
    "score_mapper_2 = {\"Low\":1,\n",
    "                \"Medium\":2,\n",
    "                 \"Barely More Than Medium\":2.1,\n",
    "                \"High\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "481dc134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    2.0\n",
       "4    3.0\n",
       "5    2.1\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_df_1[\"Score\"].replace(score_mapper_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a53ea",
   "metadata": {},
   "source": [
    "## 5.3 Encoding Dictionaries of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb061a95",
   "metadata": {},
   "source": [
    "Converting a Dictionary into feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb8cdc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "837cfd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary\n",
    "\n",
    "data_dict = [{\"Red\" : 2, \"Blue\" : 4},\n",
    "            {\"Red\" : 4, \"Blue\" : 3},\n",
    "            {\"Red\" : 1, \"Yellow\" : 2},\n",
    "            {\"Red\" : 2, \"Yellow\": 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "732054d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary vectorizer: to transform dict-like object to vectors\n",
    "\n",
    "dictvectorizer = DictVectorizer(sparse = False)\n",
    "# sparse matrix is true by default: sparse matrix stores only non-zero elements\n",
    "# sprse matrix is useful when we want to minimize the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "690599ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bf71c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictvectorizer = DictVectorizer().fit_transform(data_dict)\n",
    "# dictvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8cb85d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Blue', 'Red', 'Yellow'], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names of genereated feature\n",
    "\n",
    "feature_names = dictvectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9b6e7832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Red</th>\n",
       "      <th>Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue  Red  Yellow\n",
       "0   4.0  2.0     0.0\n",
       "1   3.0  4.0     0.0\n",
       "2   0.0  1.0     2.0\n",
       "3   0.0  2.0     2.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas to view the output in a better way\n",
    "\n",
    "pd.DataFrame(features, columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "357d50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex: for a set of documents we have a dictionary each, which contains number times a word appears in the document\n",
    "\n",
    "# word count dictionaries for four documents\n",
    "\n",
    "doc1_wordCount = {\"Red\" : 2, \"Blue\" : 4}\n",
    "doc2_wordCount = {\"Red\" : 4, \"Blue\" : 3}\n",
    "doc3_wordCount = {\"Red\" : 1, \"Yellow\" : 2}\n",
    "doc4_wordCount = {\"Red\" : 2, \"Yellow\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9c6f93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a lost with 4 doct count dictionaries\n",
    "\n",
    "word_counts = [doc1_wordCount,\n",
    "              doc2_wordCount,\n",
    "              doc3_wordCount,\n",
    "              doc4_wordCount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8ed553d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictvectorizer.fit_transform(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b6f363",
   "metadata": {},
   "source": [
    "## 5.4 Imputing Missing class values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870fc55a",
   "metadata": {},
   "source": [
    "Replacing missing values with predicted values.\n",
    "Caan be done by training a machine learning classifier algorithm(KNN classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "770699cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8fe0a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a feature matrix with categorical feature.\n",
    "# categorical feature- first column\n",
    "\n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "              [1, 1.18, 1.33],\n",
    "              [0, 1.22, 1.27],\n",
    "              [1, -0.21, -1.19]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ebf3ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding missing values to categorical feature.\n",
    "\n",
    "X_nan = np.array([[np.nan, 0.87, 1.31],\n",
    "                  [np.nan, -0.67, -0.22]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5b763941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the KNN\n",
    "\n",
    "clf = KNeighborsClassifier(3, weights='distance')\n",
    "\n",
    "# 3- number of neighbors to use.\n",
    "# weights- \"uniform\": All points in the neighborhood are weighted equally\n",
    "#         \"distance\": nearest points have more influence than that are farther away.\n",
    "\n",
    "trained_model = clf.fit(X[:,1:], X[:,0])\n",
    "\n",
    "# X[:,1:]- training data\n",
    "# X[:,0]- target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "87e60965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting missing values\n",
    "\n",
    "imputed_values = trained_model.predict(X_nan[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fb310b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "10071641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining predicted class with other features\n",
    "\n",
    "X_imputed = np.hstack((imputed_values.reshape(-1,1),X_nan[:,1:]))\n",
    "# hstack- similar to concatenation(adds to the next column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f809cbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 1.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining 2 feature matrices\n",
    "\n",
    "np.vstack((X_imputed, X))\n",
    "# vstack- similar to concatenation(adds to the next row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ca4b3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVE: We can also fill missing values with most frequent value in the data set\n",
    "\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fb907718",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_whole = np.vstack((X_nan,X))\n",
    "\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "# strategy: 'mean'- replaces missing values with mean along each column\n",
    "#           'meadian'- replaces missing values with median along each column\n",
    "#           'most_frequent'- replaces missing values with most frequent value along the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "022128e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 0.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit_transform(X_whole)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9f6669",
   "metadata": {},
   "source": [
    "## 5.5 Handling Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7c819642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When a target vector has highly imbalnaced classes we can:\n",
    "#     Collecting more data/Changing the metrics(evaluation metrics)/considering built-in class weight parameters/up-scaling/down-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f633a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b7f85e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading a dataset from scikit learn\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d124061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a feature matrix\n",
    "\n",
    "feature_iris = iris.data\n",
    "\n",
    "# creating a target vector\n",
    "\n",
    "target_iris = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c4afde96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris dataset contains 3 balanced classes of 50 observations\n",
    "# to unbalance the dataset- removing first 40 observations\n",
    "\n",
    "feature_iris = feature_iris[40:,:]\n",
    "target_iris = target_iris[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "30889db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2a36df17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a binary vector where if element is 0 then making 0 and 1 otherwise\n",
    "target_iris = np.where((target_iris == 0), 0, 1)\n",
    "\n",
    "target_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "adff945a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 0.9, 1: 0.1})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={0: 0.9, 1: 0.1})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.9, 1: 0.1})"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"RandomForestClassifier\" in scikit learn offers a \"class_weight\" parameter to handle imbalances in the dataset\n",
    "\n",
    "# creating weights\n",
    "\n",
    "weights = {0: .9, 1: 0.1}\n",
    "\n",
    "# creating random forest classifier with weights\n",
    "\n",
    "RandomForestClassifier(class_weight = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "715c99db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can directly give \"balanced\" which automatically creates weights inversely proportional class frequencies\n",
    "\n",
    "RandomForestClassifier(class_weight = \"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6bf7c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can downsample majority classes and upsample minority classes according to the observations\n",
    "\n",
    "# Example\n",
    "\n",
    "# Indices of each class observations\n",
    "\n",
    "iris_class0 = np.where(target_iris == 0)[0]\n",
    "iris_class1 = np.where(target_iris == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f141bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of observations in each class\n",
    "\n",
    "n_class0 = len(iris_class0)\n",
    "n_class1 = len(iris_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "08c1b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsampling the \"class1\" to size of \"class0\" without replacing\n",
    "\n",
    "class1_downsampled = np.random.choice(iris_class1, size = n_class0, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3ad430e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining class0 target vector with class1 downsampled vector\n",
    "\n",
    "np.hstack((target_iris[iris_class0],target_iris[class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "88ee55db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining feature matrices of class0 and downsampled class1\n",
    "\n",
    "np.vstack((feature_iris[iris_class0,:], feature_iris[class1_downsampled,:]))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e2e72a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also upsample the minor dataset\n",
    "\n",
    "# for every observation in majority class we randomly select an observation from minority class\n",
    "\n",
    "class0_upsampled = np.random.choice(iris_class0, size = n_class1, replace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9ac9424c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((target_iris[class0_upsampled],target_iris[iris_class1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "80047e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.3, 3.7, 1.5, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5.1, 3.8, 1.9, 0.4]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining upsampled class0 and class1 feature matrix\n",
    "\n",
    "np.vstack((feature_iris[class0_upsampled,:],feature_iris[iris_class1,:]))[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b15df5",
   "metadata": {},
   "source": [
    "Stratergies for handling imbalanced datasets:\n",
    "    \n",
    "    I. To collect more observations, espcially of minority classes. (best stratergy)\n",
    "    II. We can use better suited model evaluation metric. (since accuracy is used for performance, this can be ill suited)\n",
    "    III. We can use class weighing parameter options in some models. (many scikit-learn classifiers have class_weight parameter)\n",
    "    IV/V. Upsampling and Downsampling. (Choosing either option is context-specific and its good to try both) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032930e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e6832a6",
   "metadata": {},
   "source": [
    "KEYPOINTS:\n",
    "    \n",
    "    *Machine learning algorithms expect data to be in the form of matrix, one such way to transform is by using scikit learns DictVectorizer\n",
    "    \n",
    "    *KNN is a Supervised ML, K-means is Unsupervised ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34de69f5",
   "metadata": {},
   "source": [
    "KEYWORDS:\n",
    "    \n",
    "    one_hot encoding- conversion of categorical data into a format that is fed into machine learning algorithm\n",
    "    \n",
    "    fit_transform- fir into a model and transform it into a form suitable for model in a single step\n",
    "    \n",
    "    LabelBinarizer- takes categorical data and returns numpy array\n",
    "    \n",
    "    MultiLabelBinarizer- takes multiclass categorical data and returns numpy array\n",
    "    \n",
    "    DictVectorizer- transforms dict-like objects to vectors\n",
    "    \n",
    "    KNeighborsClassifier- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b001e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
